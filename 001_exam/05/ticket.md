# Экзаменационный билет №5 

## Задание

### Вопрос 1 

Прямой доступ к памяти.

### Вопрос 2 

Организация многозадачности на однопроцессорных системах, виды многозадачности.

### Практическое задание

Произвести перманентную модификацию системы, обеспечив перезагрузку машины при успешной попытке удаленного подключения к системе под пользователем «dos».

## Ответы

### Ответ 1 

Отличный вопрос! Прямой доступ к памяти (DMA — Direct Memory Access) — это фундаментальный механизм, который позволяет устройствам ввода-вывода обмениваться данными с оперативной памятью **без постоянного участия центрального процессора (CPU)**. Это критически важно для производительности, особенно для высокоскоростных устройств (сетевые карты, диски, видеокарты, USB-контроллеры).

1.  **Проблема без DMA:** При передаче данных (например, с диска в память) CPU должен был бы в цикле считывать каждый байт из порта устройства и записывать его в память. Это отнимает 100% его времени на операцию ввода-вывода.
2.  **Решение с DMA:** В систему добавляется отдельный специализированный контроллер — **DMA-контроллер**. Процессор лишь настраивает его:
    *   Говорит: "возьми данные с устройства X" (например, сетевой карты).
    *   Указывает **физический адрес** в оперативной памяти, куда нужно положить данные.
    *   Указывает размер данных.
    *   Дает команду "Старт!".
3.  **Работа DMA-контроллера:** Контроллер самостоятельно управляет шиной памяти, выполняет передачу данных из устройства в память (или наоборот) и по окончании генерирует **прерывание**, чтобы сообщить процессору: "Задача выполнена, данные готовы, можешь их обрабатывать".

**Архитектурные уровни организации DMA в Linux*

A. Аппаратный уровень
*   **Современные устройства (Bus Mastering):** У большинства современных устройств (PCI/PCIe) есть **встроенный DMA-контроллер**. Они сами являются "хозяевами шины" (bus masters) и могут напрямую инициировать чтение/запись в системную память. Это самый производительный вариант.
*   **Системный DMA-контроллер:** Устаревшие устройства (ISA) используют общий системный DMA-контроллер (каналы 0-7). Linux до сих пор поддерживает этот режим для совместимости, но он медленнее и сложнее в настройке.

B. Уровень ядра Linux (самое важное для понимания)

Ядро предоставляет целый набор API для безопасной и эффективной работы с DMA. Ключевые концепции:

1.  **Адресация:**
    *   **Физический адрес (PA):** Реальный адрес ячейки в оперативной памяти, который "видит" устройство и DMA-контроллер.
    *   **Виртуальный адрес (VA):** Адрес, с которым работает код в ядре (`void *`).
    *   **Задача:** Получить непрерывный (во многих случаях) участок физической памяти, с которым может работать устройство, и сопоставить его с виртуальным адресом для драйвера.

2.  **Типы памяти для DMA:**
    *   **Когерентная (согласованная) DMA-память (Coherent / Consistent DMA):**
        *   Выделяется через `dma_alloc_coherent()`.
        *   **Гарантирует**, что кэши процессора и содержимое этой памяти синхронизированы автоматически.
        *   Используется для небольших структур данных, которые постоянно читаются/пишутся и процессором, и устройством (например, дескрипторы команд и статусов).
        *   Медленнее в выделении, обычно небольшого размера.
    *   **Потоковая DMA-память (Streaming DMA):**
        *   Выделяется обычными методами ядра (например, `kmalloc`), но для работы с DMA требует специальных операций.
        *   **Не гарантирует** автоматическую когерентность кэша.
        *   Перед тем как отдать память устройству (на запись), драйвер **должен** явно "вымыть" (flush) данные из кэша процессора в память командой `dma_sync_single_for_device()`.
        *   Перед тем как читать данные от устройства (после завершения DMA), драйвер **должен** сделать кэш "недействительным" (invalidate) командой `dma_sync_single_for_cpu()`.
        *   Это **основной и наиболее производительный** способ для передачи больших объемов данных (буферы сетевых пакетов, блоки дисковых данных).

3.  **Ограничения устройств (DMA Mask / Зона DMA):**
    *   Старые 32-битные устройства могут адресовать только первые 4 ГБ физической памяти. Ядро должно гарантировать, что выделит буфер в этой "зоне DMA" (`GFP_DMA` флаг).
    *   Современные 64-битные устройства могут адресовать всю память. Ограничение задается с помощью `dma_set_mask_and_coherent()`.

4.  **Scatter-Gather Lists (SGL):**
    *   Реальная жизнь: буфер данных в памяти часто состоит из **нескольких несмежных фрагментов** (разных страниц памяти).
    *   Scatter-Gather позволяет настроить одну DMA-операцию для передачи такого "разбросанного" буфера.
    *   Устройству передается **список (массив) дескрипторов**, каждый из которых содержит физический адрес начала фрагмента и его длину.
    *   Это крайне эффективно и широко используется (например, сетевые стеки и файловые системы работают со страницами памяти, которые не всегда смежны).

3. Как организуется работа с DMA (для разработчика драйвера)

**Типичный сценарий для приема данных (например, сетевого пакета):**

1.  **Выделение памяти:** Драйвер заранее выделяет пул буферов (память `streaming` типа, часто с использованием SGL).
2.  **Подготовка к DMA:** Драйвер вызывает `dma_map_single()` или `dma_map_sg()`. Эта функция:
    *   Убеждается, что память доступна устройству (проверяет маску).
    *   **Синхронизирует кэш** (выполняет необходимые flush/invalidate операции).
    *   Возвращает **физический адрес (DMA-адрес)**, который нужно передать устройству.
3.  **Настройка устройства:** Драйвер записывает полученный DMA-адрес и размер в специальные регистры устройства. Затем дает команду "начать прием данных".
4.  **Запуск DMA:** Устройство начинает самостоятельно писать данные напрямую в системную память по указанному адресу.
5.  **Ожидание завершения:** Устройство генерирует прерывание по окончании передачи.
6.  **Обработка завершения:** В обработчике прерывания драйвер:
    *   **Отменяет отображение DMA:** Вызывает `dma_unmap_single()` / `dma_unmap_sg()`.
    *   **Синхронизирует кэш для CPU:** Вызывает `dma_sync_single_for_cpu()`, чтобы процессор увидел актуальные данные, пришедшие от устройства.
    *   Передает данные (например, сетевой пакет) выше по стеку ядра.
    *   Возвращает буфер в пул или выделяет новый для следующей операции.

4. Контроль со стороны ядра

Ядро строго контролирует процесс DMA для безопасности и стабильности системы:
*   **Изоляция:** DMA одного устройства не может повредить память ядра или других процессов, если драйвер настроен корректно.
*   **Драйверы в пользовательском пространстве (UIO, VFIO):** Существуют механизмы, позволяющие выделять память для DMA и работать с прерываниями из пользовательского пространства. Это используется, например, для ускоренных драйверов виртуальных машин (KVM) или высокопроизводительных пользовательских приложений, работающих с FPGA. В этом случае ядро лишь инициализирует устройство и управляет прерываниями, а вся работа с данными идет из userspace.

**Как это работает:** DMA — это аппаратная передача данных между устройством и памятью без CPU.
**Как это организовано в Linux:** Через сложную, но хорошо структурированную подсистему ядра, которая предоставляет драйверам API для:
*   Безопасного выделения "DMA-способной" памяти.
*   Синхронизации кэшей процессора и памяти.
*   Работы с непрерывными и разбросанными (scatter-gather) буферами.
*   Учета аппаратных ограничений устройств.

Это позволяет достичь максимальной производительности ввода-вывода, разгружая CPU для выполнения прикладных задач.

### Ответ 2 

Ключевой парадокс, который лежит в основе: **как на одном процессорном ядре, которое может выполнять только одну инструкцию за раз, может "одновременно" работать множество программ?**

Ответ: **Иллюзия параллелизма создается за счет очень быстрого переключения контекста между задачами.** Система по очереди выделяет каждой задаче короткий квант процессорного времени (например, 10-100 миллисекунд). Для пользователя это выглядит как одновременная работа, потому что переключения происходят сотни раз в секунду.

Существует два принципиально разных подхода к организации этой очереди и переключению между задачами.

1. Вытесняющая многозадачность (Preemptive Multitasking)

**Кто управляет переключением:** **Ядро операционной системы** (планировщик, scheduler).
**Принцип работы:**
*   Ядро выделяет каждой задаче (процессу или потоку) фиксированный или динамический **квант времени** (time slice).
*   Когда квант времени истекает, аппаратный таймер генерирует **прерывание**.
*   Ядро получает управление, приостанавливает текущую задачу (сохраняет её контекст: регистры процессора, указатель стека и т.д.) и **выбирает следующую задачу** из очереди готовых к выполнению.
*   Управление передается следующей задаче (восстанавливается её контекст).

**Ключевые особенности:**
*   **Централизованное управление:** Планировщик ОС решает, какая задача и сколько будет выполняться.
*   **Приоритетность:** Можно назначать приоритеты задачам (например, ввод с клавиатуры — высокий, фоновый расчет — низкий).
*   **Защита от "зависания":** Даже если одна задача ушла в бесконечный цикл, планировщик рано или поздно её вытеснит и отдаст CPU другой. Это основа стабильности современных ОС.
*   **Требует аппаратной поддержки:** Таймер и механизм прерываний — обязательны.

**Где используется:** **Все современные ОС общего назначения (Windows, Linux, macOS, Android)** для разделения времени между процессами пользователя и системными задачами.

2. Кооперативная многозадачность (Cooperative / Non-Preemptive Multitasking)

**Кто управляет переключением:** **Сама выполняющаяся задача.**
**Принцип работы:**
*   Задача выполняется на процессоре **столько, сколько она сама считает нужным**.
*   Когда задача решает, что может уступить процессор (например, закончила тяжелые вычисления, начала ожидание ввода или просто по доброй воле), она **явно вызывает функцию переключения** (например, `yield()` или `switch()`).
*   Управление передается следующей задаче в очереди.

**Ключевые особенности:**
*   **Доверие к задачам:** Система надеется, что задачи "воспитанные" и будут добровольно отдавать CPU.
*   **Нет защиты:** Если задача не отдает управление (попадает в бесконечный цикл без вызова переключения), **вся система "зависает"**.
*   **Меньше накладных расходов:** Нет необходимости в обработке прерываний таймера и сложных алгоритмах планирования.
*   **Проще реализация:** Не требуется сохранение/восстановление контекста по прерыванию в том же объеме, что и при вытеснении.

**Где использовалась/используется:**
*   **Ранние ОС:** Windows 3.x, классическая Mac OS (до версии 9).
*   **Специализированные среды и библиотеки:** Многие игровые движки, микроконтроллерные ОС (RTOS), среды выполнения языков, где управление задачами — часть самого языка (например, ранние версии Green Threads в Java, корутины в Python до `asyncio`, модель акторов в Erlang/Elixir).

Как это организовано на однопроцессорной системе? (Составляющие)

1.  **Очередь готовых задач:** Планировщик ОС поддерживает список задач, готовых к выполнению (не заблокированных вводом/выводом или сном).

2.  **Контекст задачи:** Для каждого процесса/потока в памяти хранится структура данных (Process Control Block, PCB / Thread Control Block), которая содержит:
    *   Идентификатор (PID/TID).
    *   Состояние (выполняется, готов, ожидает).
    *   Значения регистров процессора на момент приостановки.
    *   Указатель на адресное пространство (для процессов).
    *   Указатель на стек.
    *   Приоритет и другую служебную информацию.

3.  **Механизм переключения контекста (Context Switch):**
    *   Это **дорогая операция**, так как требует сохранения/восстановления множества регистров и может приводить к сбросу кэша процессора.
    *   При вытесняющей многозадачности инициируется по прерыванию от таймера.
    *   Алгоритм: сохранить регистры текущей задачи в её PCB -> выбрать следующую задачу из очереди -> загрузить её регистры из её PCB -> переключить адресное пространство (если это другой процесс) -> передать управление.

4.  **Состояния задачи:**
    *   **Выполняется (Running):** Использует CPU.
    *   **Готов (Ready):** Готов к выполнению, ждет своей очереди в планировщике.
    *   **Ожидание/Блокирован (Waiting/Blocked):** Ждет события (завершения ввода/вывода, сигнала, освобождения ресурса). Не конкурирует за CPU.
    *   Переходы между этими состояниями и управление очередями — это и есть сердце планировщика.

Краткое сравнение в таблице

| Критерий | Вытесняющая многозадачность | Кооперативная многозадачность |
| :--- | :--- | :--- |
| **Кто решает о переключении** | Ядро ОС (планировщик) | Сама выполняющаяся задача |
| **Реакция на "зависшую" задачу** | Вытеснит, система продолжит работу | **Вся система блокируется** |
| **Накладные расходы** | Выше (обработка прерываний, сложный планировщик) | Ниже |
| **Детерминизм времени отклика** | Сложнее гарантировать (зависит от других задач) | Проще, если задачи "воспитанные" |
| **Типичное применение** | Универсальные ОС, многопользовательские системы | Специализированные системы, игровые движки, ранние ОС |

Итог

На однопроцессорной системе **многозадачность — это искусная иллюзия**, создаваемая быстрым переключением между задачами. **Вытесняющий** подход доминирует в современных системах, так как обеспечивает отказоустойчивость и честное распределение ресурсов. **Кооперативный** подход остается нишевым, используемым там, где требуется минимальные накладные расходы и полный контроль над выполнением внутри самой среды.
